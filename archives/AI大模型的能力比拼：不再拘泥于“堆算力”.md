在当下大模型快速发展的时代，提到谁家的AI大模型更为优秀，许多人会直接将“算力”作为衡量标准。无论是开源还是闭源的大模型，其核心几乎都源自谷歌研究团队在2017年发布的《Attention is All You Need》论文中提出的“Transformer模型”。从特斯拉的自动驾驶FSD到OpenAI的ChatGPT，几乎所有现有的大模型都可以看作是“Transformer模型”的变种。

## 算力堆叠的局限性

当前，AI大模型的竞争主要集中在算力的投入上。例如，OpenAI在2025年训练GPT-4时使用了25000张英伟达A100 GPU。据报道，OpenAI目前至少拥有40万块英伟达的GB200和H100芯片。类似地，甲骨文和特斯拉也在争取更多的算力资源。然而，这种“堆算力”的发展模式让行业缺乏变革的可能性。

## DeepSeek-V3：打破传统的创新者

2025年1月，中国初创企业DeepSeek推出的大语言模型（LLM）DeepSeek-V3引发了全球关注。根据测评机构Artificial Analysis的独立分析，DeepSeek-V3在文本理解、编码、数学和学科知识等方面表现优异，甚至超越了Meta的Llama 3.1-405B和阿里巴巴的Qwen 2.5-72B等开源模型。在性能上，它与OpenAI的GPT-4o和Anthropic的Claude 3.5 Sonnet等顶尖闭源模型不相上下。

DeepSeek-V3的优势不仅体现在性能上，还在于其极高的性价比。与其他模型动辄需要1.6万到10万个GPU的集群不同，DeepSeek-V3仅用了2048张英伟达H800显卡，在57天内完成了训练，成本仅为约557.6万美元。这一成本仅为GPT-4训练成本的十分之一。

## 高效的训练与成本优势

DeepSeek-V3的训练数据令人印象深刻：2048张H800显卡，两个月时间，训练出了一个拥有6710亿参数的超大规模模型。相比之下，硅谷公司通常需要使用更高端的显卡，并投入数倍的算力和成本。Meta的同等能力模型训练成本高达数亿美元，而DeepSeek-V3的性价比无疑为行业树立了新标杆。

## 行业专家的评价

盘古智库专家胡延平认为，DeepSeek-V3的成功证明了行业大模型路线的可行性。虽然与通用大模型相比仍有差距，但其更贴合产业化落地的需求，尤其适合中国AI赋能各行各业的目标。

值得注意的是，DeepSeek-V3的发布甚至对英伟达的股价产生了影响。一些华尔街分析师指出，这一事件让市场对“堆算力”模式的可持续性产生了质疑。

## 未来的AI发展方向

DeepSeek-V3的成功表明，AI大模型的发展不必拘泥于算力的堆叠。通过更高效的算法、更低的成本和更贴近实际需求的设计，AI技术有望在更多领域实现突破。

👉 [WildCard | 一分钟注册，轻松订阅海外线上服务](https://bit.ly/bewildcard)