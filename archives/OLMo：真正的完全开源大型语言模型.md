OLMo 是一个由 AI2 组织推出的真正意义上的 100% 开源项目，致力于为研究人员提供全面的开放资源。

## OLMo 的主要特点

1. **完整的预训练数据**  
   OLMo 完全开放了其训练所用的 Dolma 数据集，其中包含高达 3 万亿 token 的数据。这让研究人员不仅能够访问模型本身，还可以获取原始数据，以深入理解模型的训练基础，从而对模型进行微调。

2. **训练和推理工具**  
   OLMo 提供了四个不同变体模型的完整模型权重，每个模型训练至少使用 2 万亿个 token。此外，用户可获得训练代码、推理代码、训练指标和日志，确保模型训练过程的复现性。

3. **评估工具**  
   OLMo 项目还包括了开发过程中使用的评估套件，涵盖 500 多个模型检查点，并附带完整的评估代码。这为研究人员进行性能分析和模型评估提供了便利。

## 模型参数和架构

OLMo 提供了不同规模的模型变体，包括：

- **1B（10亿参数）模型**：配备 16 层、每层 2048 个隐藏单元和 16 个注意力头，训练至少 2 万亿个 token。
- **7B（70亿参数）模型**：具有 32 层、每层 4086 个隐藏单元和 32 个注意力头，训练约 2.46 万亿个 token。
- **65B（650亿参数）模型**：正在训练中，计划包含 80 层、每层 8192 个隐藏单元和 64 个注意力头。

模型采用基于 Vaswani 等（2017年）的解码器仅 Transformer 架构，并进行了多项改进，例如：

- 不使用偏置项以提高训练稳定性。
- 采用非参数层归一化。
- 使用 SwiGLU 激活函数代替 ReLU。
- 引入旋转位置嵌入（RoPE）。
- 使用修改版的 BPE 基于的标记器，降低了个人可识别信息（PII）。

## 预训练数据：Dolma 数据集

OLMo 使用的 Dolma 数据集为一个多元化、来源广泛的 3 万亿 token 语料库，包含来自 7 种不同数据源的 5 亿文档，涵盖了网络页面、代码、社交媒体、STEM 论文、书籍和百科资料等多种内容。

## 性能评估

在多项生成和阅读理解任务中，OLMo 7B 的表现与 Llama 2 相当，但在一些流行的问答任务上表现略逊。在应用 AI2 的 Paloma 和可用检查点的帮助下，分析了模型规模与其预测语言能力间的关系。

👉 [野卡 | 一分钟注册，轻松订阅海外线上服务](https://bit.ly/bewildcard)

## 访问项目

欲了解更多信息，请访问 [OLMo 官方网站](https://allenai.org/olmo)。